{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Pipeline for Running YOLOv8 Model for Image Classification\n",
    "\n",
    "- The unified framework from YOLOv8 (You Only Look Once version 8) can handle both object detection and classification, making it versatile for tasks requiring both capabilities. Also, this model incorporates modern deep learning techniques and optimizations, providing a good balance of speed and accuracy. Finally, it has a mature API for fine-tuning our own dataset.\n",
    "\n",
    "- Seealso [yuting public repo](https://github.com/ytsimon2004/deep_imgcls)\n",
    "    - [pipleine](https://github.com/ytsimon2004/deep_imgcls/blob/main/src/imgcls/classification/yolov8/pipeline.py)\n",
    "    - [notebook example](https://github.com/ytsimon2004/deep_imgcls/tree/main/notebook)\n",
    "\n",
    "\n",
    "- For more information on training modes, visit [Ultralytics Documentation](https://docs.ultralytics.com/modes/train/).\n",
    "    - Avalible model type: `yolov8n`, `yolov8s`, `yolov8m`, `yolov8l`, `yolov8x`\n",
    "\n",
    "\n",
    "## Follow the data folder structure as outlined below**:\n",
    "```\n",
    "SOURCE_ROOT_DIR (in the kaggle demo below, use '/kaggle/working')\n",
    "    │\n",
    "    ├── dataset.yml (1)\n",
    "    ├── runs/ (2)\n",
    "    │   └── detect\n",
    "    │         ├── predict*\n",
    "    │         │    ├── labels/\n",
    "    │         │    ├── test_*.png\n",
    "    │         │    └── test_set.csv (5)\n",
    "    │         ├── train*\n",
    "    │         │    ├── <yolo outputs>\n",
    "    │         │    └── weights/ (6)\n",
    "    │         └── *yolov8s.pt\n",
    "    │\n",
    "    ├── test/ (3)\n",
    "    │   ├── img/\n",
    "    │   ├── img_png/\n",
    "    │   └── test_set.csv\n",
    "    │\n",
    "    └── train (4)\n",
    "        ├── img/\n",
    "        ├── img_png/\n",
    "        ├── seg/\n",
    "        ├── seg_png/\n",
    "        └── train_set.csv\n",
    "        \n",
    "```\n",
    "    (1) config yaml file for the custom path info/image labels\n",
    "    \n",
    "    (2) directory for model/train/evaluation output files\n",
    "    \n",
    "    (3) directory for test dataset\n",
    "    \n",
    "    (4) directory for train dataset\n",
    "\n",
    "    (5) output results of classification\n",
    "    \n",
    "    (6) store the fine-tuned model weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:48:09.965962Z",
     "iopub.status.busy": "2024-05-18T21:48:09.965579Z",
     "iopub.status.idle": "2024-05-18T21:48:26.507182Z",
     "shell.execute_reply": "2024-05-18T21:48:26.506070Z",
     "shell.execute_reply.started": "2024-05-18T21:48:09.965933Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:48:26.509697Z",
     "iopub.status.busy": "2024-05-18T21:48:26.509371Z",
     "iopub.status.idle": "2024-05-18T21:48:34.000566Z",
     "shell.execute_reply": "2024-05-18T21:48:33.999762Z",
     "shell.execute_reply.started": "2024-05-18T21:48:26.509645Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import final, Final, Literal, NamedTuple\n",
    "from typing_extensions import TypeAlias\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import yaml\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt, patches\n",
    "from skimage.measure import regionprops, label\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from colorama import Fore, Style\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:48:34.002267Z",
     "iopub.status.busy": "2024-05-18T21:48:34.001780Z",
     "iopub.status.idle": "2024-05-18T21:48:34.007148Z",
     "shell.execute_reply": "2024-05-18T21:48:34.005906Z",
     "shell.execute_reply.started": "2024-05-18T21:48:34.002231Z"
    }
   },
   "outputs": [],
   "source": [
    "# handle wandb API checking bug\n",
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Class/Function\n",
    "- copy from personal repo for easilier usage in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "ClassInt: TypeAlias = int  # image class\n",
    "ClassName: TypeAlias = str  # image class name\n",
    "DetectClassSquare: TypeAlias = dict[ClassInt, list[tuple[float, float, float, float]]]  # cls: [xc, yc, w, h]\n",
    "\n",
    "YOLO8_MODEL_TYPE = Literal['yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x']\n",
    "\n",
    "# ================ #\n",
    "# Utility Function #\n",
    "# ================ #\n",
    "\n",
    "def copy_directory_contents(src_dir: Path | str, dst_dir: Path | str) -> None:\n",
    "    \"\"\"copy all contents from one the another directory\"\"\"\n",
    "    src_path = Path(src_dir)\n",
    "    dst_path = Path(dst_dir)\n",
    "    dst_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        for item in src_path.iterdir():\n",
    "            dst_item = dst_path / item.name\n",
    "            if item.is_dir():\n",
    "                shutil.copytree(item, dst_item, dirs_exist_ok=True)\n",
    "            else:\n",
    "                shutil.copy2(item, dst_item)\n",
    "        fprint(f'All contents copied from {src_dir} to {dst_dir} successfully.')\n",
    "    except Exception as e:\n",
    "        fprint(f'Error: {e}', vtype='error')\n",
    "\n",
    "        \n",
    "def fprint(*msgs,\n",
    "           vtype: Literal['info', 'io', 'warning', 'error', 'pass'] = 'info',\n",
    "           timestamp: bool = True,\n",
    "           **kwarg) -> None:\n",
    "    \"\"\"\n",
    "    Formatting print with different colors based on verbose type\n",
    "\n",
    "    :param msgs:\n",
    "    :param vtype: verbose type\n",
    "    :param timestamp: if print timestamp\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    if vtype == 'error':\n",
    "        prefix = '[ERROR]'\n",
    "        color = 'red'\n",
    "    elif vtype == 'warning':\n",
    "        prefix = '[WARNING] '\n",
    "        color = 'yellow'\n",
    "    elif vtype == 'io':\n",
    "        prefix = '[IO] '\n",
    "        color = 'magenta'\n",
    "    elif vtype == 'info':\n",
    "        prefix = '[INFO]'\n",
    "        color = 'cyan'\n",
    "    elif vtype == 'pass':\n",
    "        prefix = '[PASS]'\n",
    "        color = 'green'\n",
    "    else:\n",
    "        raise ValueError(f'{vtype}')\n",
    "\n",
    "    try:\n",
    "        fg_color = getattr(Fore, color.upper())\n",
    "    except AttributeError:\n",
    "        fg_color = Fore.WHITE\n",
    "\n",
    "    msg = fg_color + prefix\n",
    "    if timestamp:\n",
    "        msg += f\"[{datetime.today().strftime('%y-%m-%d %H:%M:%S')}] - \"\n",
    "\n",
    "    try:\n",
    "        out = f\"{''.join(msgs)}\\n\"\n",
    "    except TypeError:\n",
    "        out = f'{msgs}'\n",
    "\n",
    "    msg += out\n",
    "    msg += Style.RESET_ALL\n",
    "    print(msg, **kwarg)\n",
    "\n",
    "\n",
    "def check_mps_available() -> bool:\n",
    "    \"\"\"for edge mac machine MPS backend check\"\"\"\n",
    "    if not torch.backends.mps.is_available():\n",
    "        if not torch.backends.mps.is_built():\n",
    "            fprint('MPS not available because pytorch install not built with MPS enable', vtype='warning')\n",
    "        else:\n",
    "            fprint('MPS not available because current MacOs version is not 12.3+,'\n",
    "                   ' or do not have MPS-enabled device on this machine', vtype='warning')\n",
    "        return False\n",
    "    else:\n",
    "        fprint('MPS is available', vtype='pass')\n",
    "        return True\n",
    "\n",
    "# ============================= #\n",
    "# Utility Function For Pipeline #\n",
    "# ============================= #\n",
    "\n",
    "def clone_png_dir(directory: Path | str,\n",
    "                  resize_dim: tuple[int, int] | None = None) -> None:\n",
    "    \n",
    "    \"\"\"Clone batch raw .npy files to png in a separated folder, image resize if needed\n",
    "\n",
    "    :param directory: directory contains .npy files\n",
    "    :param resize_dim: resize dim in (w, h) if not None\n",
    "    \"\"\"\n",
    "    dst = Path(directory).parent / f'{directory.stem}_png'\n",
    "    if not dst.exists():\n",
    "        dst.mkdir()\n",
    "\n",
    "    files = list(Path(directory).glob('*.npy'))\n",
    "    iter_file = tqdm(files,\n",
    "                     total=len(files),\n",
    "                     unit='file',\n",
    "                     desc=f'npy clone and resize as png to {dst}')\n",
    "\n",
    "    for file in iter_file:\n",
    "        img = np.load(file)\n",
    "        if resize_dim is not None:\n",
    "            img = cv2.resize(img, dsize=resize_dim, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        out = (dst / file.name).with_suffix('.png')\n",
    "        plt.imsave(out, img)\n",
    "\n",
    "def detect_segmented_objects(seg_arr: np.ndarray, min_area: int = 500) -> DetectClassSquare:\n",
    "    \"\"\"\n",
    "    Detects objects in a segmented image array and returns their center, width, and height.\n",
    "\n",
    "    :param seg_arr: array of the segmented image where different values represent different objects\n",
    "    :param min_area: minimum area threshold to consider an object. smaller areas are ignored\n",
    "    :return: A dictionary where keys are object classes and values are lists of tuples containing\n",
    "    (x_center, y_center, width, height) for each object of that class.\n",
    "    \"\"\"\n",
    "\n",
    "    objects_info = {}\n",
    "\n",
    "    # the unique values in the image array represent different classes\n",
    "    object_classes = np.unique(seg_arr)\n",
    "    # exclude the background class (value equal to 0)\n",
    "    object_classes = object_classes[object_classes != 0]\n",
    "\n",
    "    for object_class in object_classes:\n",
    "        class_mask = (seg_arr == object_class)\n",
    "\n",
    "        # label connected regions of the mask\n",
    "        label_img = label(class_mask)\n",
    "        regions = regionprops(label_img)\n",
    "\n",
    "        class_objects_info = []\n",
    "        for region in regions:\n",
    "\n",
    "            if region.area < min_area:\n",
    "                continue\n",
    "\n",
    "            y0, x0, y1, x1 = region.bbox\n",
    "            x_center = (x0 + x1) / 2\n",
    "            y_center = (y0 + y1) / 2\n",
    "            width = x1 - x0\n",
    "            height = y1 - y0\n",
    "            class_objects_info.append((x_center, y_center, width, height))\n",
    "\n",
    "        objects_info[object_class - 1] = class_objects_info  # 1-base to 0-base\n",
    "\n",
    "    return objects_info\n",
    "\n",
    "        \n",
    "def write_yolo_label_txt(img_filepath: str | Path,\n",
    "                         detected: DetectClassSquare,\n",
    "                         img_dim: tuple[int, int],\n",
    "                         output_dir: str | Path) -> None:\n",
    "    \"\"\"\n",
    "    Write detected object as yolov8 required label file for train dataset ::\n",
    "\n",
    "        <class_id> <xc> <y_center> <width> <height>\n",
    "    \n",
    "    :param img_filepath: image filepath\n",
    "    :param detected: `DetectClassSquare`\n",
    "    :param img_dim: image dimension\n",
    "    :param output_dir: txt output directory\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    filename = Path(img_filepath).stem\n",
    "    out = (Path(output_dir) / filename).with_suffix('.txt')\n",
    "\n",
    "    width, height = img_dim\n",
    "    with open(out, 'w') as file:\n",
    "        for cls, info in detected.items():\n",
    "            for (xc, yc, w, h) in info:\n",
    "                x_center_normalized = xc / width\n",
    "                y_center_normalized = yc / height\n",
    "                width_normalized = w / width\n",
    "                height_normalized = h / height\n",
    "                content = f'{cls} {x_center_normalized} {y_center_normalized} {width_normalized} {height_normalized}\\n'\n",
    "                file.write(content)\n",
    "                \n",
    "                \n",
    "def dir_ipy_imshow(directory: Path | str,\n",
    "                   pattern: str = '*.png') -> None:\n",
    "    \"\"\"\n",
    "    Display images from a directory with a button to load the next image\n",
    "\n",
    "    :param directory: directory contain image sequences\n",
    "    :param pattern: glob pattern in the directory\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from IPython.display import display\n",
    "    from IPython.core.display import clear_output\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "    files = sorted(list(Path(directory).glob(pattern)), key=lambda it: int(it.stem.split('_')[1]))\n",
    "    iter_files = iter(files)\n",
    "\n",
    "    image_display = widgets.Image()\n",
    "    button = widgets.Button(description=\"Next Image\")\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        try:\n",
    "            file = next(iter_files)\n",
    "        except StopIteration:\n",
    "            clear_output(wait=True)\n",
    "        else:\n",
    "            with open(file, 'rb') as f:\n",
    "                img = f.read()\n",
    "            image_display.value = img\n",
    "\n",
    "    button.on_click(on_button_clicked)\n",
    "    display(button)\n",
    "    display(image_display)\n",
    "    on_button_clicked(None)\n",
    "\n",
    "# ======================= #\n",
    "# Folder Structure Handle #\n",
    "# ======================= #\n",
    "\n",
    "\n",
    "class ImageClsDir(NamedTuple):\n",
    "    \"\"\"Class for folder structure for train/test dataset and model/prediction output\"\"\"\n",
    "    root_dir: Path\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_dir(p: Path):\n",
    "        \"\"\"auto mkdir, use for custom dir that fit for yolo pipeline\"\"\"\n",
    "        p.mkdir(exist_ok=True)\n",
    "        return p\n",
    "\n",
    "    # ============= #\n",
    "    # Train Dataset #\n",
    "    # ============= #\n",
    "\n",
    "    @property\n",
    "    def train_data_dir(self) -> Path:\n",
    "        return self.root_dir / 'train'\n",
    "\n",
    "    @property\n",
    "    def train_image_source(self) -> Path:\n",
    "        return self.train_data_dir / 'img'\n",
    "\n",
    "    @property\n",
    "    def train_image_png(self) -> Path:\n",
    "        return self.ensure_dir(self.train_data_dir / 'img_png')\n",
    "\n",
    "    @property\n",
    "    def train_seg_source(self) -> Path:\n",
    "        return self.train_data_dir / 'seg'\n",
    "\n",
    "    @property\n",
    "    def train_seg_png(self) -> Path:\n",
    "        return self.ensure_dir(self.train_data_dir / 'seg_png')\n",
    "\n",
    "    @property\n",
    "    def train_dataframe(self) -> pl.DataFrame:\n",
    "        return pl.read_csv(self.train_data_dir / 'train_set.csv')\n",
    "\n",
    "    # ============ #\n",
    "    # Test Dataset #\n",
    "    # ============ #\n",
    "\n",
    "    @property\n",
    "    def test_data_dir(self) -> Path:\n",
    "        return self.root_dir / 'test'\n",
    "\n",
    "    @property\n",
    "    def test_image_source(self) -> Path:\n",
    "        return self.test_data_dir / 'img'\n",
    "\n",
    "    @property\n",
    "    def test_image_png(self) -> Path:\n",
    "        return self.ensure_dir(self.test_data_dir / 'img_png')\n",
    "\n",
    "    # ================ #\n",
    "    # Model Train/Eval #\n",
    "    # ================ #\n",
    "\n",
    "    @property\n",
    "    def run_dir(self) -> Path:\n",
    "        return self.root_dir / 'runs' / 'detect'\n",
    "\n",
    "    def get_predict_dir(self, name: str) -> Path:\n",
    "        return self.run_dir / name\n",
    "\n",
    "    def get_predict_label_dir(self, name: str) -> Path:\n",
    "        return self.get_predict_dir(name) / 'labels'\n",
    "\n",
    "    def get_train_dir(self, name: str = 'train') -> Path:\n",
    "        return self.run_dir / name\n",
    "\n",
    "    def get_model_weights(self, name: str = 'train') -> Path:\n",
    "        return self.run_dir / name / 'weights'\n",
    "\n",
    "    \n",
    "# =========================================== #\n",
    "# Main Pipeline for YOLO classification model #\n",
    "# =========================================== #\n",
    "\n",
    "@final\n",
    "class YoloUltralyticsPipeline:\n",
    "    \"\"\"Custom pipeline for implementing the YOLOv8 from ultralytics\n",
    "\n",
    "    .. seealso :: `<https://docs.ultralytics.com/modes/train/>`_\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_dir: str | Path, *,\n",
    "                 model_type: YOLO8_MODEL_TYPE = 'yolov8n',\n",
    "                 model_path: str | Path | None = None,\n",
    "                 resize_dim: tuple[int, int] | None = None,\n",
    "                 use_gpu: bool = False,\n",
    "                 epochs: int = 10,\n",
    "                 batch_size: int = 32):\n",
    "        \"\"\"\n",
    "\n",
    "        :param root_dir: `SOURCE_ROOT_DIR`. aka. input data source \n",
    "        :param model_type: {'yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x'}\n",
    "        :param model_path: model path (If already trained)\n",
    "        :param resize_dim: (w,h) resize for image \n",
    "        :param use_gpu: whether use gpu for fine-tuned the model\n",
    "        :param epochs: number of the training epoch\n",
    "        :param batch_size: training bathc size\n",
    "        \"\"\"\n",
    "        self.image_dir = ImageClsDir(root_dir)\n",
    "        self.resize_dim = resize_dim\n",
    "\n",
    "        # label_dict, order sensitive\n",
    "        df = self.image_dir.train_dataframe.drop('Id')\n",
    "        self.label_dict: Final[dict[ClassInt, ClassName]] = {\n",
    "            i: df.columns[i]\n",
    "            for i in range(df.shape[1])\n",
    "        }\n",
    "\n",
    "        # training/prediction parameters\n",
    "        self.model_type = model_type\n",
    "        self.model = model_path  # if already fine-tuned. If None, then auto-inferred\n",
    "        self._epochs = epochs\n",
    "        self._lr0 = 0.01\n",
    "        self._batch = batch_size\n",
    "        self._train_filename: str | None = None  # incremental folder name, assign foreach train\n",
    "        self._predict_filename: str | None = None  # incremental folder name, assign foreach predict\n",
    "\n",
    "        # resources\n",
    "        self._device = None  # torch.device('cpu')?\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                fprint('Process using cuda GPU')\n",
    "                self._device = torch.device('cuda')\n",
    "            elif check_mps_available():  # use cpu mode or increase the batch size if NMS time issue\n",
    "                fprint('Process using mps GPU')\n",
    "                self._device = torch.device('mps')\n",
    "                self._lr0 = 0.00025\n",
    "            else:\n",
    "                fprint('none acceleration backend found', vtype='warning')\n",
    "        \n",
    "    def run(self) -> None:\n",
    "        \"\"\"main for pipeline if run in one-go\"\"\"\n",
    "        # if fine-tuned model already specified\n",
    "        if self.model is None:\n",
    "            self.clone_png_dir()\n",
    "            self.gen_yaml()\n",
    "            self.gen_label_txt(debug_mode=False)\n",
    "            self.yolo_train(model_type=self.model_type)\n",
    "            self.yolo_predict(self.predict_filename)\n",
    "            self.create_predicted_csv()\n",
    "        else:\n",
    "            self.yolo_predict(self.model)\n",
    "            self.create_predicted_csv()\n",
    "    \n",
    "    @property\n",
    "    def n_test(self) -> int:\n",
    "        return len(list(self.image_dir.test_image_png.glob('*.png')))\n",
    "\n",
    "    @property\n",
    "    def train_filename(self) -> str:\n",
    "        if self._train_filename is None:\n",
    "            raise RuntimeWarning('run model train first')\n",
    "        return self._train_filename\n",
    "\n",
    "    @property\n",
    "    def predict_filename(self) -> str:\n",
    "        if self._predict_filename is None:\n",
    "            raise RuntimeWarning('run model predict first')\n",
    "        return self._predict_filename\n",
    "\n",
    "    @property\n",
    "    def cur_train_dir(self) -> Path:\n",
    "        \"\"\"current train directory\"\"\"\n",
    "        return self.image_dir.get_train_dir(self.train_filename)\n",
    "\n",
    "    @property\n",
    "    def cur_predict_dir(self) -> Path:\n",
    "        return self.image_dir.get_predict_dir(self.predict_filename)\n",
    "\n",
    "    @property\n",
    "    def cur_predict_label_dir(self) -> Path:\n",
    "        return self.image_dir.get_predict_label_dir(self.predict_filename)\n",
    "    \n",
    "    def clone_png_dir(self) -> None:\n",
    "        \"\"\"Clone batch raw .npy files to png in a separated folder, image resize if needed\"\"\"\n",
    "        fprint('<STATE 1> -> clone png dir')\n",
    "\n",
    "        clone_png_dir(self.image_dir.train_image_source, self.resize_dim)\n",
    "        clone_png_dir(self.image_dir.train_seg_source, self.resize_dim)\n",
    "        clone_png_dir(self.image_dir.test_image_source)  # no need resize for prediction\n",
    "    \n",
    "    def gen_yaml(self, output: Path | str | None = None, verbose: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Generate the yaml for yolov8 config\n",
    "\n",
    "        :param output: output filepath of the yaml file\n",
    "        :param verbose: show output verbose\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        fprint('<STATE 2> -> generate yaml file')\n",
    "\n",
    "        if output is None:\n",
    "            output = self.image_dir.root_dir / 'dataset.yml'\n",
    "\n",
    "        dy = {\n",
    "            'path': str(self.image_dir.root_dir),\n",
    "            'train': str(self.image_dir.train_image_png),\n",
    "            'val': str(self.image_dir.train_image_png),\n",
    "            'test': str(self.image_dir.test_image_png),\n",
    "            'names': self.label_dict\n",
    "        }\n",
    "\n",
    "        with open(output, 'w') as file:\n",
    "            yaml.safe_dump(dy, file, sort_keys=False)\n",
    "\n",
    "        if verbose:\n",
    "            with open(output, 'rb') as file:\n",
    "                config = yaml.safe_load(file)\n",
    "                pprint(config)\n",
    "                \n",
    "    def gen_label_txt(self, debug_mode: bool = True, min_area: int = 500) -> None:\n",
    "        \"\"\"\n",
    "        Detect the object edge from seg files and generate the yolov8 required label file for train dataset ::\n",
    "\n",
    "        <class_id> <xc> <y_center> <width> <height>\n",
    "\n",
    "        :param debug_mode: debug mode to see the train dataset segmentation result\n",
    "        :param min_area: minimum area threshold to consider an object. smaller areas are ignored\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        fprint('<STATE 3> -> auto annotate segmentation file and generate label txt')\n",
    "\n",
    "        files = sorted(list(self.image_dir.train_seg_source.glob('*.npy')),\n",
    "                       key=lambda it: int(it.stem.split('_')[1]))\n",
    "\n",
    "        iter_seg = tqdm(files,\n",
    "                        total=len(files),\n",
    "                        unit='file',\n",
    "                        ncols=80,\n",
    "                        desc='detect edge')\n",
    "\n",
    "        for seg in iter_seg:\n",
    "            im = np.load(seg)\n",
    "\n",
    "            if self.resize_dim is not None:\n",
    "                im = cv2.resize(im, dsize=self.resize_dim, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            detected = detect_segmented_objects(im, min_area=min_area)\n",
    "\n",
    "            if debug_mode:\n",
    "                fprint(f'IMAGE -> {seg.stem}')\n",
    "                fprint(f'DETECTED RESULT -> {detected}')\n",
    "                fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "                # query raw\n",
    "                _, _, idx = seg.stem.partition('_')\n",
    "                file = list(self.image_dir.train_image_png.glob(f'*_{idx}.png'))[0]\n",
    "                raw = Image.open(str(file))\n",
    "                ax[0].imshow(raw)\n",
    "\n",
    "                ax[1].imshow(im)\n",
    "\n",
    "                # draw\n",
    "                colors = plt.cm.rainbow(np.linspace(0, 1, 20))\n",
    "                legend_handles = []\n",
    "                for cls, info in detected.items():\n",
    "                    color = colors[cls % len(colors)]  # cycle through colors\n",
    "                    for (xc, yc, width, height) in info:\n",
    "                        rect = patches.Rectangle((xc - width / 2, yc - height / 2),\n",
    "                                                 width, height,\n",
    "                                                 linewidth=1,\n",
    "                                                 edgecolor=color,\n",
    "                                                 facecolor='none')\n",
    "                        ax[0].add_patch(rect)\n",
    "\n",
    "                    legend_patch = patches.Patch(color=color, label=self.label_dict[cls])\n",
    "                    legend_handles.append(legend_patch)\n",
    "\n",
    "                ax[0].legend(handles=legend_handles, loc='best')\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "            #\n",
    "            write_yolo_label_txt(seg, detected,\n",
    "                                 self.resize_dim if self.resize_dim is not None else im.shape,\n",
    "                                 output_dir=self.image_dir.train_image_png)\n",
    "\n",
    "    def yolo_train(self, model_type: YOLO8_MODEL_TYPE = 'yolov8n',\n",
    "                   save: bool = True) -> None:\n",
    "        \"\"\"Load a pretrained model for training\"\"\"\n",
    "        fprint(f'<STATE 4> -> Train the dataset using {model_type}')\n",
    "        model_path = (self.image_dir.run_dir / model_type).with_suffix('.pt')\n",
    "        model = YOLO(model_path)\n",
    "\n",
    "        model.train(data=self.image_dir.root_dir / 'dataset.yml',\n",
    "                    device=self._device,\n",
    "                    batch=self._batch,\n",
    "                    lr0=self._lr0,\n",
    "                    # project=self.image_dir.run_dir, # bug from wandb dependency\n",
    "                    epochs=self._epochs,\n",
    "                    cache=True)\n",
    "\n",
    "        self._train_filename = model.overrides['name']\n",
    "\n",
    "        if save:\n",
    "            model.export(format='onnx')\n",
    "\n",
    "    def yolo_predict(self, model_path: Path | str | None = None,\n",
    "                     save_plot: bool = True,\n",
    "                     save_txt: bool = True):\n",
    "        \"\"\"\n",
    "        Do the model prediction\n",
    "        \n",
    "        :param model_path: If None, use directly the last train model. Otherwise, specify the model path directly \n",
    "        :param save_plot: Save predict plot\n",
    "        :param save_txt: Save the predict txt (DetectClassSquare for each image)\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        fprint('<STATE 5> -> Predicted result using test dataset')\n",
    "\n",
    "        if model_path is None:\n",
    "            model_path = self.image_dir.get_model_weights(self._train_filename) / 'best.pt'\n",
    "\n",
    "        model = YOLO(model_path)\n",
    "        model.predict(source=self.image_dir.test_image_png,\n",
    "                      save=save_plot,\n",
    "                      save_txt=save_txt,\n",
    "                      project=self.image_dir.run_dir)\n",
    "\n",
    "        self._predict_filename = model.predictor.save_dir.name\n",
    "                   \n",
    "    def create_predicted_csv(self, verbose: bool = True) -> pl.DataFrame:\n",
    "        \"\"\"create output csv\"\"\"\n",
    "        fprint('<STATE 6> -> Write predicted result to csv')\n",
    "\n",
    "        ret = {}\n",
    "        for txt in self.cur_predict_label_dir.glob('test*.txt'):\n",
    "            classes = set()\n",
    "            with open(txt, 'r') as file:\n",
    "                for line in file:\n",
    "                    cls = line.split(' ')[0]\n",
    "                    classes.add(cls)\n",
    "\n",
    "            _, _, idx = txt.stem.partition('_')\n",
    "            ret[idx] = list(classes)\n",
    "\n",
    "        ret = dict(sorted(ret.items()))\n",
    "\n",
    "        #\n",
    "        dy = dict(Id=np.arange(self.n_test))\n",
    "        for i, field in enumerate(self.label_dict.values()):\n",
    "            dy[field] = np.full(self.n_test, 0)\n",
    "\n",
    "        df = pl.DataFrame(dy)\n",
    "\n",
    "        for i, classes in ret.items():\n",
    "            for cls in classes:\n",
    "                df[int(i), self.label_dict[int(cls)]] = 1\n",
    "\n",
    "        dst = self.cur_predict_dir / 'test_set.csv'\n",
    "        df.write_csv(dst)\n",
    "        fprint(f'Successful create result in {dst}', vtype='io')\n",
    "        \n",
    "        if verbose:\n",
    "            print(df)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # ============================================== #\n",
    "    # Visualization of Intermediate Training Metrics #\n",
    "    # ============================================== #\n",
    "\n",
    "    @classmethod\n",
    "    def _fig_show(cls, p, size):\n",
    "        fig = Image.open(p)\n",
    "        plt.figure(figsize=size)\n",
    "        plt.imshow(fig)\n",
    "        plt.axis('off')\n",
    "\n",
    "    @classmethod\n",
    "    def show_confusion_matrix(cls, train_dir: Path | str):\n",
    "        p = Path(train_dir) / 'confusion_matrix_normalized.png'\n",
    "        cls._fig_show(p, (10, 10))\n",
    "\n",
    "    @classmethod\n",
    "    def show_epochs_progress(cls, train_dir: Path | str):\n",
    "        p = Path(train_dir) / 'results.png'\n",
    "        cls._fig_show(p, (10, 5))\n",
    "\n",
    "    @classmethod\n",
    "    def get_epochs_progress_dataframe(cls, train_dir: Path | str) -> pl.DataFrame:\n",
    "        p = Path(train_dir) / 'results.csv'\n",
    "        df = pd.read_csv(p)  # casting purpose\n",
    "        return pl.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the customize YOLOv8 classification pipeline step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:52:24.497474Z",
     "iopub.status.busy": "2024-05-18T21:52:24.496730Z",
     "iopub.status.idle": "2024-05-18T21:52:52.934634Z",
     "shell.execute_reply": "2024-05-18T21:52:52.933684Z",
     "shell.execute_reply.started": "2024-05-18T21:52:24.497442Z"
    }
   },
   "outputs": [],
   "source": [
    "# To fit our pipeline, Copy dataset to kaggle `output` since `input` dir in READ-only\n",
    "copy_directory_contents(src_dir='/kaggle/input/kul-h02a5a-computer-vision-ga2-2024', dst_dir='/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T23:12:24.903062Z",
     "iopub.status.busy": "2024-05-18T23:12:24.902200Z",
     "iopub.status.idle": "2024-05-18T23:12:24.910441Z",
     "shell.execute_reply": "2024-05-18T23:12:24.909495Z",
     "shell.execute_reply.started": "2024-05-18T23:12:24.903027Z"
    }
   },
   "outputs": [],
   "source": [
    "# init our customized pipeline (enable CUDA kernel for accerlation)\n",
    "yolo = YoloUltralyticsPipeline(root_dir=Path('/kaggle/working/'), \n",
    "                               resize_dim=(500, 500), \n",
    "                               model_type='yolov8n',\n",
    "                               use_gpu=True,\n",
    "                               epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1** - Clone batch raw .npy files to png in a separated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:52:59.212360Z",
     "iopub.status.busy": "2024-05-18T21:52:59.211731Z",
     "iopub.status.idle": "2024-05-18T21:55:39.795926Z",
     "shell.execute_reply": "2024-05-18T21:55:39.794931Z",
     "shell.execute_reply.started": "2024-05-18T21:52:59.212330Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo.clone_png_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2** - Generate the yaml for yolov8 config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:57:42.614678Z",
     "iopub.status.busy": "2024-05-18T21:57:42.613983Z",
     "iopub.status.idle": "2024-05-18T21:57:42.628346Z",
     "shell.execute_reply": "2024-05-18T21:57:42.627226Z",
     "shell.execute_reply.started": "2024-05-18T21:57:42.614624Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo.gen_yaml(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3** - Detect the object edge from seg files and generate the yolo8 required label file for train dataset\n",
    "- Each object example: \\<class_id\\> \\<xc\\> \\<y_center\\> \\<width\\> \\<height\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T21:57:46.170223Z",
     "iopub.status.busy": "2024-05-18T21:57:46.169336Z",
     "iopub.status.idle": "2024-05-18T21:57:52.720765Z",
     "shell.execute_reply": "2024-05-18T21:57:52.719690Z",
     "shell.execute_reply.started": "2024-05-18T21:57:46.170192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use debug mode=True to see the detected examples \n",
    "yolo.gen_label_txt(debug_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4/5** - Load a pretrained model for training & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T23:12:43.291573Z",
     "iopub.status.busy": "2024-05-18T23:12:43.290719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Option 1: If not yet fine-tuned the model. \n",
    "yolo.yolo_train()\n",
    "yolo.yolo_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the intermediate figures from training/validation\n",
    "### 1. Metrics throughout training/validation epochs\n",
    "\n",
    "- `box_loss`: **bounding box regression loss during training**. It measures how well the predicted bounding boxes align with the ground truth bounding boxes. A decreasing trend indicates that the model is improving its bounding box predictions as training progresses.\n",
    "  \n",
    "- `cls_loss`: **classification loss during training**. It measures how well the model is classifying the objects within the bounding boxes. A decreasing trend indicates that the model is getting better at classifying objects correctly.\n",
    "  \n",
    "- `dfl_loss`: **distribution focal loss during training**. This loss typically focuses on the quality of the bounding box prediction, enhancing the performance on difficult examples. A decreasing trend indicates improving performance.\n",
    "\n",
    "- `precision(B)`: **precision metric for the model on the training dataset**. Precision measures the proportion of true positive detections out of all positive detections (true positives + false positives). An increasing trend indicates the model is making fewer false positive errors.\n",
    "\n",
    "- `recall(B)`:  **recall metric for the model on the training dataset**. Recall measures the proportion of true positive detections out of all actual positives (true positives + false negatives). An increasing trend indicates the model is detecting more true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = yolo.cur_train_dir\n",
    "print(YoloUltralyticsPipeline.get_epochs_progress_dataframe(train_dir))\n",
    "YoloUltralyticsPipeline.show_epochs_progress(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Confusion matrix\n",
    " - During the model validation procedure, represent the normalized count of predictions for each class (0-1 in colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YoloUltralyticsPipeline.show_confusion_matrix(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: If a fine-tuned model already exists. directly load\n",
    "model_path =  ... # e.g., '/kaggle/working/runs/detect/train/weights/best.pt'\n",
    "yolo.yolo_predict(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T22:41:08.800026Z",
     "iopub.status.busy": "2024-05-18T22:41:08.799636Z",
     "iopub.status.idle": "2024-05-18T22:41:08.819098Z",
     "shell.execute_reply": "2024-05-18T22:41:08.818211Z",
     "shell.execute_reply.started": "2024-05-18T22:41:08.799997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Brief interactive way to examine the predicted results using test dataset\n",
    "predict_dir = yolo.image_dir.get_predict_dir(yolo.predict_filename)\n",
    "dir_ipy_imshow(predict_dir, pattern='*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6** - Create csv for classified test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T22:41:15.153435Z",
     "iopub.status.busy": "2024-05-18T22:41:15.152732Z",
     "iopub.status.idle": "2024-05-18T22:41:15.282546Z",
     "shell.execute_reply": "2024-05-18T22:41:15.281562Z",
     "shell.execute_reply.started": "2024-05-18T22:41:15.153404Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yolo.create_predicted_csv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9575f28"
   },
   "source": [
    "# 4. Adversarial attack\n",
    "For this part, your goal is to fool your classification and/or segmentation CNN, using an *adversarial attack*. More specifically, the goal is build a CNN to perturb test images in a way that (i) they look unperturbed to humans; but (ii) the CNN classifies/segments these images in line with the perturbations."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7751254,
     "sourceId": 70925,
     "sourceType": "competition"
    },
    {
     "datasetId": 5032125,
     "sourceId": 8445167,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 151.961305,
   "end_time": "2022-04-12T14:50:45.298914",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-12T14:48:13.337609",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
